{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the python notebook to train various ML models for ai face image identification task. The first step is to download the dataset using the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (2.2.2)\n",
      "Requirement already satisfied: bleach in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guobuzai/miniconda3/envs/ml/lib/python3.12/site-packages (from requests->kaggle) (3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, tarfile, kaggle, zipfile; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"ai_faces\": \"chelove4draste/5k-ai-generated-faces\",\n",
    "    \"real_faces\": \"atulanandjha/lfwpeople\"\n",
    "}\n",
    "\n",
    "# Local download paths\n",
    "download_dir = \"./datasets\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and unzip Kaggle datasets\n",
    "def download_and_extract(dataset_name, kaggle_path, target_dir):\n",
    "    print(f\"Downloading {dataset_name}...\")\n",
    "    kaggle.api.dataset_download_files(kaggle_path, path=target_dir, unzip=True)\n",
    "    print(f\"{dataset_name} downloaded and extracted to {target_dir}\")\n",
    "# Function to check if a dataset is already downloaded\n",
    "def is_dataset_downloaded(target_dir):\n",
    "    # Check if the directory exists and contains files\n",
    "    return os.path.exists(target_dir) and any(os.scandir(target_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_faces dataset is already downloaded at ./datasets\\ai_faces.\n",
      "real_faces dataset is already downloaded at ./datasets\\real_faces.\n",
      "Datasets are checked, downloaded, and organized.\n"
     ]
    }
   ],
   "source": [
    "# Download and extract datasets if not already downloaded\n",
    "for name, kaggle_path in datasets.items():\n",
    "    dataset_path = os.path.join(download_dir, name)\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    \n",
    "    if is_dataset_downloaded(dataset_path):\n",
    "        print(f\"{name} dataset is already downloaded at {dataset_path}.\")\n",
    "    else:\n",
    "        download_and_extract(name, kaggle_path, dataset_path)\n",
    "\n",
    "print(\"Datasets are checked, downloaded, and organized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ./datasets\\real_faces\\lfw-funneled.tgz to ./datasets\\real_faces\n"
     ]
    }
   ],
   "source": [
    "lfw_tgz_path = os.path.join(download_dir, \"real_faces\", \"lfw-funneled.tgz\")\n",
    "extract_path = os.path.join(download_dir, \"real_faces\")\n",
    "\n",
    "# Function to extract .tgz files\n",
    "def extract_tgz(file_path, target_dir):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "    with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=target_dir)\n",
    "    print(f\"Extracted {file_path} to {target_dir}\")\n",
    "\n",
    "# Extract the LFW dataset\n",
    "extract_tgz(lfw_tgz_path, extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all the initial datasets are downloaded. We will load 4000 of each of the dataset and then randomly pick 2500 of each to be the trainingset, and 750 of each to be validation set, and the rest to be test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing files in directory: ./datasets/ai_faces/5k\n",
      "Found 5000 files in AI faces directory.\n",
      "First 5 files: ['./datasets/ai_faces/5k\\\\seed300000.png', './datasets/ai_faces/5k\\\\seed300001.png', './datasets/ai_faces/5k\\\\seed300002.png', './datasets/ai_faces/5k\\\\seed300003.png', './datasets/ai_faces/5k\\\\seed300004.png']\n",
      "Listing files in directory: ./datasets/real_faces/lfw_funneled\n",
      "Found 13233 files in Real faces directory.\n",
      "First 5 files: ['./datasets/real_faces/lfw_funneled\\\\Aaron_Eckhart\\\\Aaron_Eckhart_0001.jpg', './datasets/real_faces/lfw_funneled\\\\Aaron_Guiel\\\\Aaron_Guiel_0001.jpg', './datasets/real_faces/lfw_funneled\\\\Aaron_Patterson\\\\Aaron_Patterson_0001.jpg', './datasets/real_faces/lfw_funneled\\\\Aaron_Peirsol\\\\Aaron_Peirsol_0001.jpg', './datasets/real_faces/lfw_funneled\\\\Aaron_Peirsol\\\\Aaron_Peirsol_0002.jpg']\n"
     ]
    }
   ],
   "source": [
    "ai_faces_dir = \"./datasets/ai_faces/5k\"\n",
    "real_faces_dir = \"./datasets/real_faces/lfw_funneled\"\n",
    "\n",
    "# Function to list files in a directory\n",
    "def list_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "        return []\n",
    "    print(f\"Listing files in directory: {directory}\")\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(directory):  # Walk through the directory\n",
    "        for file in filenames:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):  # Filter for image files\n",
    "                files.append(os.path.join(root, file))\n",
    "    return files\n",
    "\n",
    "# List files in AI faces directory\n",
    "ai_faces_files = list_files(ai_faces_dir)\n",
    "print(f\"Found {len(ai_faces_files)} files in AI faces directory.\")\n",
    "print(f\"First 5 files: {ai_faces_files[:5]}\")\n",
    "\n",
    "# List files in Real faces directory\n",
    "real_faces_files = list_files(real_faces_dir)\n",
    "print(f\"Found {len(real_faces_files)} files in Real faces directory.\")\n",
    "print(f\"First 5 files: {real_faces_files[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (10.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image) (23.2)\n",
      "Collecting networkx>=2.8\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting imageio>=2.33\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image) (10.2.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\louis\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image) (1.12.0)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.36.1 lazy-loader-0.4 networkx-3.4.2 scikit-image-0.24.0 tifffile-2024.9.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy \n",
    "!pip install pillow\n",
    "!pip install scikit-learn\n",
    "!pip install scikit-image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2gray\n",
    "import numpy.random as r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images into an array\n",
    "def load_images_to_array(file_paths, img_size):\n",
    "    images = []\n",
    "    for filepath in file_paths:\n",
    "        try:\n",
    "            img = Image.open(filepath).convert(\"RGB\")  # Ensure RGB format\n",
    "            img = img.resize(img_size)  # Resize to target size\n",
    "            images.append(np.array(img) / 255.0)  # Normalize pixel values\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI faces array shape: (2000, 128, 128, 3)\n",
      "Real faces array shape: (2000, 128, 128, 3)\n",
      "Images have been processed and saved to numpy arrays.\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "IMG_SIZE = (128, 128)  # Resize all images to 128x128\n",
    "MAX_IMAGES = 2000  # Limit the number of images\n",
    "\n",
    "# Preprocess AI faces\n",
    "ai_faces_array = load_images_to_array(ai_faces_files[:MAX_IMAGES], IMG_SIZE)\n",
    "print(f\"AI faces array shape: {ai_faces_array.shape}\")\n",
    "\n",
    "# Preprocess Real faces\n",
    "real_faces_array = load_images_to_array(real_faces_files[:MAX_IMAGES], IMG_SIZE)\n",
    "print(f\"Real faces array shape: {real_faces_array.shape}\")\n",
    "\n",
    "# Save to numpy arrays\n",
    "np.save(\"ai_faces.npy\", ai_faces_array)\n",
    "np.save(\"real_faces.npy\", real_faces_array)\n",
    "\n",
    "print(\"Images have been processed and saved to numpy arrays.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Train: (1250, 128, 128, 3), Validation: (400, 128, 128, 3), Test: (350, 128, 128, 3)\n",
      "Real Train: (1250, 128, 128, 3), Validation: (400, 128, 128, 3), Test: (350, 128, 128, 3)\n",
      "Training Set: X_train: (2500, 128, 128, 3), y_train: (2500,)\n",
      "Validation Set: X_val: (800, 128, 128, 3), y_val: (800,)\n",
      "Test Set: X_test: (700, 128, 128, 3), y_test: (700,)\n"
     ]
    }
   ],
   "source": [
    "# Load the numpy arrays\n",
    "ai_faces = np.load(\"ai_faces.npy\")\n",
    "real_faces = np.load(\"real_faces.npy\")\n",
    "\n",
    "# Define dataset sizes\n",
    "train_size = 1250\n",
    "val_size = 400\n",
    "\n",
    "# Function to split the data randomly\n",
    "def split_data(data, train_size, val_size):\n",
    "    indices = np.random.permutation(len(data))  # Shuffle indices\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    return data[train_indices], data[val_indices], data[test_indices]\n",
    "\n",
    "# Split AI faces\n",
    "ai_train, ai_val, ai_test = split_data(ai_faces, train_size, val_size)\n",
    "print(f\"AI Train: {ai_train.shape}, Validation: {ai_val.shape}, Test: {ai_test.shape}\")\n",
    "\n",
    "# Split Real faces\n",
    "real_train, real_val, real_test = split_data(real_faces, train_size, val_size)\n",
    "print(f\"Real Train: {real_train.shape}, Validation: {real_val.shape}, Test: {real_test.shape}\")\n",
    "\n",
    "# Combine training, validation, and test sets\n",
    "X_train = np.concatenate((ai_train, real_train), axis=0)\n",
    "y_train = np.array([0] * len(ai_train) + [1] * len(real_train))  # 0 = AI, 1 = Real\n",
    "\n",
    "X_val = np.concatenate((ai_val, real_val), axis=0)\n",
    "y_val = np.array([0] * len(ai_val) + [1] * len(real_val))\n",
    "\n",
    "X_test = np.concatenate((ai_test, real_test), axis=0)\n",
    "y_test = np.array([0] * len(ai_test) + [1] * len(real_test))\n",
    "\n",
    "# Shuffle the datasets for better training\n",
    "train_indices = np.random.permutation(len(X_train))\n",
    "val_indices = np.random.permutation(len(X_val))\n",
    "test_indices = np.random.permutation(len(X_test))\n",
    "\n",
    "X_train, y_train = X_train[train_indices], y_train[train_indices]\n",
    "X_val, y_val = X_val[val_indices], y_val[val_indices]\n",
    "X_test, y_test = X_test[test_indices], y_test[test_indices]\n",
    "\n",
    "# Output the shapes of the final datasets\n",
    "print(f\"Training Set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Validation Set: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"Test Set: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initialization is completed and loaded to np arrays, it is time to start trying various techniques of ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first aspect to try is simple NN, using sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(images):\n",
    "    return np.array([rgb2gray(image) for image in images])  # Convert each image to grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = convert_to_grayscale(X_train)\n",
    "X_val_gray = convert_to_grayscale(X_val)\n",
    "X_test_gray = convert_to_grayscale(X_test)\n",
    "\n",
    "# Reshape the images to 1D arrays (flattened)\n",
    "X_train_flat = X_train_gray.reshape(X_train_gray.shape[0], -1)\n",
    "X_val_flat = X_val_gray.reshape(X_val_gray.shape[0], -1)\n",
    "X_test_flat = X_test_gray.reshape(X_test_gray.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect_binary(y):\n",
    "    y_vect = np.zeros((len(y), 2))  # Binary classification: 2 classes (AI, Real)\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_v_train = convert_y_to_vect_binary(y_train)\n",
    "y_v_val = convert_y_to_vect_binary(y_val)\n",
    "y_v_test = convert_y_to_vect_binary(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the NN intialization is completed, and start NN with sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))\n",
    "\n",
    "# Initialize weights and biases\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b\n",
    "\n",
    "# Initialize gradient storage\n",
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b\n",
    "\n",
    "# Feed forward\n",
    "def feed_forward(x, W, b):\n",
    "    a = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        node_in = a[l]\n",
    "        z[l + 1] = W[l].dot(node_in) + b[l]\n",
    "        a[l + 1] = f(z[l + 1])\n",
    "    return a, z\n",
    "\n",
    "# Backpropagation\n",
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    return -(y - a_out) * f_deriv(z_out)\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print(f'Starting gradient descent for {iter_num} iterations')\n",
    "    while cnt < iter_num:\n",
    "        if cnt % 1000 == 0:\n",
    "            print(f'Iteration {cnt} of {iter_num}')\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i, :], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i, :] - a[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l + 1], W[l], z[l])\n",
    "                    tri_W[l] += np.dot(delta[l + 1][:, np.newaxis], np.transpose(a[l][:, np.newaxis]))\n",
    "                    tri_b[l] += delta[l + 1]\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0 / N * tri_W[l])\n",
    "            b[l] += -alpha * (1.0 / N * tri_b[l])\n",
    "        avg_cost = 1.0 / N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 5000 iterations\n",
      "Iteration 0 of 5000\n",
      "Iteration 1000 of 5000\n",
      "Iteration 2000 of 5000\n",
      "Iteration 3000 of 5000\n",
      "Iteration 4000 of 5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nn_structure = [128 * 128, 10,  2]\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train_flat, y_v_train, iter_num=5000)\n",
    "\n",
    "# Plot the cost function\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.title('Training Cost Over Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight is: {1: array([[0.47822842, 0.28963715, 0.62533507, ..., 0.14629625, 0.92516008,\n",
      "        0.83275967],\n",
      "       [0.70142202, 0.53677351, 0.12879248, ..., 0.45633755, 0.71509052,\n",
      "        0.16889609],\n",
      "       [0.16089854, 0.57004186, 0.23714571, ..., 0.31681852, 0.7231139 ,\n",
      "        0.53495504],\n",
      "       ...,\n",
      "       [0.760719  , 0.38680319, 0.56999166, ..., 0.97351828, 0.59145922,\n",
      "        0.54370662],\n",
      "       [0.39916035, 0.54646556, 0.99935488, ..., 0.79637601, 0.2081058 ,\n",
      "        0.94752548],\n",
      "       [0.0445871 , 0.34304581, 0.97054111, ..., 0.07459662, 0.95796359,\n",
      "        0.93953192]]), 2: array([[ 0.20434299,  0.28394679, -0.12019457, -0.05634878, -0.33044764,\n",
      "        -0.2217877 , -0.40235532, -0.06172717,  0.44808981,  0.10513848],\n",
      "       [-0.13087176, -0.16089382,  0.32837643, -0.32455975, -0.45851104,\n",
      "         0.17502644,  0.26982956,  0.24891203, -0.06254623, -0.15163171]])}\n",
      "Prediction accuracy on the test set is 50.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Weight is: {W}')\n",
    "# Evaluate on the test set\n",
    "y_pred = predict_y(W, b, X_val_flat, len(nn_structure))\n",
    "y_pred_binary = np.round(y_pred).astype(int)  # Convert predictions to binary\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "print(f'Prediction accuracy on the test set is {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression weights are: [[-0.04969402 -0.04229512 -0.03958624 ... -0.02402755 -0.0315294\n",
      "  -0.03559399]]\n",
      "Accuracy on test data: 100.00%\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       1.00      1.00      1.00       400\n",
      "        Real       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Logistic Regression Model\n",
    "logreg = linear_model.LogisticRegression(penalty=None)  # No regularization\n",
    "logreg.fit(X_train_flat, y_train)  # Use flattened grayscale images for training\n",
    "\n",
    "# Model Coefficients and Intercept\n",
    "w_logreg = logreg.coef_\n",
    "intercept_logreg = logreg.intercept_\n",
    "\n",
    "print(f'Logistic regression weights are: {w_logreg}')\n",
    "# Predictions\n",
    "y_hat_logreg = logreg.predict(X_val_flat)  # Predict on test set\n",
    "\n",
    "# Accuracy on Test Set\n",
    "acc_logreg = logreg.score(X_val_flat, y_val)\n",
    "\n",
    "print(\"Accuracy on test data: %.2f%%\" % (acc_logreg * 100))\n",
    "\n",
    "# Precision, Recall, and F-score\n",
    "prec, recal, fscore, sup = precision_recall_fscore_support(y_val, y_hat_logreg, average='binary')\n",
    "\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall: {recal:.2f}\")\n",
    "print(f\"F1-Score: {fscore:.2f}\")\n",
    "\n",
    "# Classification Report for more detailed metrics\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_hat_logreg, target_names=[\"AI\", \"Real\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying svms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.0 GiB for an array with shape (49152, 49152) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Train the SVM with the training set and evaluate using the validation set\u001b[39;00m\n\u001b[0;32m     83\u001b[0m lambda1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Regularization parameter\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m w_svm \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_svm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Make predictions on the validation set\u001b[39;00m\n\u001b[0;32m     87\u001b[0m y_val_pred_svm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(np\u001b[38;5;241m.\u001b[39mdot(X_val_scaled, w_svm))\n",
      "Cell \u001b[1;32mIn[26], line 79\u001b[0m, in \u001b[0;36mtrain_svm\u001b[1;34m(X, y, lambda1)\u001b[0m\n\u001b[0;32m     76\u001b[0m w0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(d)  \u001b[38;5;66;03m# Initialize weights to zeros\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Use scipy.optimize.minimize to minimize the objective function\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:309\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    306\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    315\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_optimize.py:402\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    398\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:185\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    182\u001b[0m                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad_impl \u001b[38;5;241m=\u001b[39m update_grad\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Hessian Evaluation\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hess):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    182\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\optimize\\_numdiff.py:584\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    582\u001b[0m n \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m    583\u001b[0m J_transposed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n, m))\n\u001b[1;32m--> 584\u001b[0m h_vecs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h\u001b[38;5;241m.\u001b[39msize):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2-point\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\twodim_base.py:293\u001b[0m, in \u001b[0;36mdiag\u001b[1;34m(v, k)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mabs\u001b[39m(k)\n\u001b[1;32m--> 293\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m         i \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.0 GiB for an array with shape (49152, 49152) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reload the dataset to ensure clean data\n",
    "# Assume `ai_faces.npy` and `real_faces.npy` are the dataset files\n",
    "ai_faces = np.load(\"ai_faces.npy\")\n",
    "real_faces = np.load(\"real_faces.npy\")\n",
    "\n",
    "# Define dataset sizes\n",
    "train_size = 1250\n",
    "val_size = 400\n",
    "\n",
    "# Function to split the data randomly\n",
    "def split_data(data, train_size, val_size):\n",
    "    indices = np.random.permutation(len(data))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    return data[train_indices], data[val_indices], data[test_indices]\n",
    "\n",
    "# Split AI and Real faces into train/validation/test sets\n",
    "ai_train, ai_val, ai_test = split_data(ai_faces, train_size, val_size)\n",
    "real_train, real_val, real_test = split_data(real_faces, train_size, val_size)\n",
    "\n",
    "# Combine datasets and labels\n",
    "X_train = np.concatenate((ai_train, real_train), axis=0)\n",
    "X_val = np.concatenate((ai_val, real_val), axis=0)\n",
    "X_test = np.concatenate((ai_test, real_test), axis=0)\n",
    "\n",
    "y_train = np.array([0] * len(ai_train) + [1] * len(real_train))\n",
    "y_val = np.array([0] * len(ai_val) + [1] * len(real_val))\n",
    "y_test = np.array([0] * len(ai_test) + [1] * len(real_test))\n",
    "\n",
    "# Flatten images and normalize features\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "# Convert labels to -1 and +1 for SVM\n",
    "y_train_svm = np.where(y_train == 0, -1, 1)\n",
    "y_val_svm = np.where(y_val == 0, -1, 1)\n",
    "y_test_svm = np.where(y_test == 0, -1, 1)\n",
    "\n",
    "# Define the SVM objective function\n",
    "def svm_objective(w, X, y, lambda1=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the SVM objective function.\n",
    "    \n",
    "    w: weights\n",
    "    X: input data\n",
    "    y: labels (-1 or +1 for SVM)\n",
    "    lambda1: regularization parameter\n",
    "    \"\"\"\n",
    "    regularization_term = (lambda1 / 2) * np.linalg.norm(w)**2\n",
    "    hinge_loss = np.maximum(0, 1 - y * (np.dot(X, w)))\n",
    "    result = regularization_term + hinge_loss.sum()\n",
    "    return result\n",
    "\n",
    "# SVM Training\n",
    "def train_svm(X, y, lambda1=0.1):\n",
    "    \"\"\"\n",
    "    Train an SVM using the objective function.\n",
    "    \n",
    "    X: input data (N x d)\n",
    "    y: labels (-1 or +1 for SVM)\n",
    "    lambda1: regularization parameter\n",
    "    \"\"\"\n",
    "    N, d = X.shape\n",
    "    w0 = np.zeros(d)  # Initialize weights to zeros\n",
    "    \n",
    "    # Use scipy.optimize.minimize to minimize the objective function\n",
    "    result = minimize(fun=svm_objective, x0=w0, args=(X, y, lambda1), method='L-BFGS-B')\n",
    "    return result.x  # Optimized weights\n",
    "\n",
    "# Train the SVM with the training set and evaluate using the validation set\n",
    "lambda1 = 0.1  # Regularization parameter\n",
    "w_svm = train_svm(X_train_scaled, y_train_svm, lambda1=lambda1)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_svm = np.sign(np.dot(X_val_scaled, w_svm))\n",
    "\n",
    "# Evaluate the SVM on the validation set\n",
    "val_accuracy = accuracy_score(y_val_svm, y_val_pred_svm)\n",
    "val_prec, val_recal, val_fscore, val_sup = precision_recall_fscore_support(y_val_svm, y_val_pred_svm, average='binary')\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Precision: {val_prec:.2f}\")\n",
    "print(f\"Validation Recall: {val_recal:.2f}\")\n",
    "print(f\"Validation F1-Score: {val_fscore:.2f}\")\n",
    "\n",
    "# Classification report on the validation set\n",
    "print(\"\\nValidation Classification Report:\\n\")\n",
    "print(classification_report(y_val_svm, y_val_pred_svm, target_names=[\"AI\", \"Real\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image.png: [Errno 2] No such file or directory: 'image.png'\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess a single image\n",
    "def preprocess_single_image(filepath, img_size):\n",
    "    \"\"\"\n",
    "    Preprocess a single image: resize, normalize, and convert to numpy array.\n",
    "    \n",
    "    filepath: Path to the image file.\n",
    "    img_size: Target size (width, height) for resizing the image.\n",
    "    \n",
    "    Returns: Preprocessed image as a numpy array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(filepath).convert(\"RGB\")  # Ensure RGB format\n",
    "        img = img.resize(img_size)  # Resize to target size\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Processed Image\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        return np.array(img) / 255.0  # Normalize pixel values\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess the sample image\n",
    "SAMPLE_IMG_SIZE = (128, 128)  # Target size for resizing\n",
    "sample_image_path = \"image.png\"  # Update to your sample image path\n",
    "\n",
    "sample_image_processed = preprocess_single_image(sample_image_path, SAMPLE_IMG_SIZE)\n",
    "\n",
    "# Check the shape of the processed image and proceed to scaling if successful\n",
    "if sample_image_processed is not None:\n",
    "    # Flatten the image to match the input of the model\n",
    "    sample_image_flat = sample_image_processed.reshape(1, -1)\n",
    "\n",
    "    # Scale the sample image using the trained StandardScaler\n",
    "    sample_image_scaled = scaler.transform(sample_image_flat)\n",
    "\n",
    "    # Use the trained SVM model to predict the label for the sample image\n",
    "    sample_image_pred = np.sign(np.dot(sample_image_scaled, w_svm))\n",
    "\n",
    "    # Map prediction to label\n",
    "    predicted_label = \"AI-Generated\" if sample_image_pred[0] == -1 else \"Real\"\n",
    "\n",
    "    # Display the result\n",
    "    print(f\"The predicted label for the sample image is: {predicted_label}\")\n",
    "\n",
    "else:\n",
    "    \"Failed to preprocess the sample image.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to have zero mean and unit variance\n",
    "# SHOULD BE IN PREVIOUS SECTION AS WELL\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_val_scaled = scaler.transform(X_val_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original labels are strings: '0','1', '2', ... '9'. Our SVM algorithm Pegasos expects the labels to be encoded as +1 and -1\n",
    "# Here we encode one digit as 1, and we encode the other 9 digits as -1\n",
    "def one_vs_rest_encoding(y, digit = '0'):\n",
    "\n",
    "    # Let y_encoded be an numpy array of encoded digits, with 1 for the digit we want to predict, and -1 for the rest\n",
    "    # This may take several lines of code, but please store your final encoding in y_encoded\n",
    "    y_encoded = y_encoded = np.array([1 if label == digit else -1 for label in y])   #// check\n",
    "    \n",
    "    return  y_encoded\n",
    "\n",
    "# Compute the score for each example in X\n",
    "def score(X, w):\n",
    "    # To do\n",
    "    return np.dot(X, w) \n",
    "\n",
    "def svm_objective(w, X, y, lambda1=.1):\n",
    "    # To do. This part may require several lines of code. \n",
    "    # Store your answer in result. \n",
    "    reg = (lambda1 / 2) * np.dot(w, w)\n",
    "    hing = np.maximum(0, 1 - y * np.dot(X, w))\n",
    "    hingSum = np.sum(hing)\n",
    "    result = reg + hingSum \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic sub-gradient descent\n",
    "def pegasos(X_train, y_train, lambda1, num_iters):\n",
    "    # Hyperparameters: threshold, lambda1\n",
    "    # parameters\n",
    "    N, d = X_train.shape  # Number of samples and features\n",
    "    t = 0  # Iteration counter\n",
    "    w = np.zeros(d)  # Initialize weight vector to zeros\n",
    "\n",
    "    for iter in range(num_iters):  # Iterate over the dataset multiple times\n",
    "        print(f\"Iteration {iter + 1}, Objective: {svm_objective(w, X_train, y_train, lambda1):.6f}\")\n",
    "\n",
    "        for i in range(N):  # Stochastic gradient descent over each sample\n",
    "            t += 1  # Increment iteration counter\n",
    "            learning_rate = 1 / (lambda1 * t)  # Learning rate schedule\n",
    "\n",
    "            # Calculate the update for this example\n",
    "            if y_train[i] * np.dot(X_train[i], w) < 1:  # If hinge loss is violated\n",
    "                w = (1 - learning_rate * lambda1) * w + learning_rate * y_train[i] * X_train[i]\n",
    "            else:  # If hinge loss is satisfied\n",
    "                w = (1 - learning_rate * lambda1) * w\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_to_predict = '0'\n",
    "y_train_encoded = one_vs_rest_encoding(y_train, digit=digit_to_predict)\n",
    "y_val_encoded = one_vs_rest_encoding(y_val, digit=digit_to_predict)\n",
    "y_test_encoded = one_vs_rest_encoding(y_test, digit=digit_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Objective: 2500.000000\n",
      "Iteration 2, Objective: 554340.493667\n",
      "Iteration 3, Objective: 295936.127427\n",
      "Iteration 4, Objective: 194006.084824\n",
      "Iteration 5, Objective: 187220.701128\n",
      "Iteration 6, Objective: 147374.749170\n",
      "Iteration 7, Objective: 114202.329349\n",
      "Iteration 8, Objective: 99871.434387\n",
      "Iteration 9, Objective: 90869.574954\n",
      "Iteration 10, Objective: 90956.829010\n"
     ]
    }
   ],
   "source": [
    "lambda1 = 0.05  # Regularization parameter\n",
    "num_iters = 10  # Number of iterations\n",
    "w_pegasos = pegasos(X_train_scaled, y_train_encoded, lambda1=lambda1, num_iters=num_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels using the score function\n",
    "y_val_scores = score(X_val_scaled, w_pegasos)\n",
    "y_val_pred = np.where(y_val_scores >= 0, 1, -1)  # Convert scores to binary predictions (+1/-1)\n",
    "\n",
    "y_test_scores = score(X_test_scaled, w_pegasos)\n",
    "y_test_pred = np.where(y_test_scores >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 50.75%\n",
      "Test Accuracy: 49.86%\n",
      "\n",
      "Validation Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AI Faces       1.00      0.51      0.67       800\n",
      "  Real Faces       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       800\n",
      "   macro avg       0.50      0.25      0.34       800\n",
      "weighted avg       1.00      0.51      0.67       800\n",
      "\n",
      "\n",
      "Test Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AI Faces       1.00      0.50      0.67       700\n",
      "  Real Faces       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       700\n",
      "   macro avg       0.50      0.25      0.33       700\n",
      "weighted avg       1.00      0.50      0.67       700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\louis\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Validation Accuracy\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test Accuracy\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nValidation Classification Report:\\n\")\n",
    "print(classification_report(y_val_encoded, y_val_pred, target_names=[\"AI Faces\", \"Real Faces\"]))\n",
    "\n",
    "print(\"\\nTest Classification Report:\\n\")\n",
    "print(classification_report(y_test_encoded, y_test_pred, target_names=[\"AI Faces\", \"Real Faces\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
